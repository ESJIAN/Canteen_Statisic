
# 适配版本

| Python 版本 | paddlepaddle  | paddleocr   | torch        | numpy     | opencv-python     |
| ----------- | ------------- | ----------- | ------------ | --------- | ----------------- |
| 3.7         | 2.1.2 ~ 2.7.0 | 2.6.0~2.7.0 | 1.7.1~2.2.0  | 1.20~1.24 | 4.2.0.34~4.6.0.66 |
| 3.8         | 2.1.2 ~ 2.7.0 | 2.6.0~2.7.0 | 1.7.1~2.2.0  | 1.20~1.24 | 4.2.0.34~4.6.0.66 |
| 3.9         | 2.1.2 ~ 2.7.0 | 2.6.0~2.7.0 | 1.8.0~2.2.0  | 1.20~1.24 | 4.2.0.34~4.6.0.66 |
| 3.10        | 2.3.0 ~ 2.7.0 | 2.6.0~2.7.0 | 1.10.0~2.2.0 | 1.21~1.24 | 4.5.5.64~4.6.0.66 |
| 3.11        | 2.5.0 ~ 2.7.0 | 2.7.0+      | 2.0.0+       | 1.23~1.26 | 4.6.0.66+         |



# 数据解读


* `dt_boxes num : 100, elapse : 2.22263503074646`
  * **dt_boxes num** ：检测到的文本框数量（即图片中检测到的文本区域数，这里是 100 个）。
  * **elapse** ：文本检测阶段耗时（单位：秒），这里是 2.22 秒。
* `cls num  : 100, elapse : 1.6745765209197998`
  * **cls num** ：需要做方向分类的文本框数量（通常与检测到的文本框数一致）。
  * **elapse** ：方向分类阶段耗时，这里是 1.67 秒。
* `rec_res num  : 100, elapse : 19.74185085296631`
  * **rec_res num** ：识别出的文本框数量（通常与前面一致）。
  * **elapse** ：文本识别阶段耗时，这里是 19.74 秒。


```
data = [
    [
        [[820.0, 34.0], [1933.0, 34.0], [1933.0, 179.0], [820.0, 179.0]], 
        ("采购验收单", 0.9970836639404297)
    ],
    [
        [[253.0, 303.0], [2221.0, 294.0], [2221.0, 397.0], [253.0, 405.0]], 
        ("购买单位第三采油厂第七作业区注采704食堂2025-04-24", 0.9800031781196594)
    ],

]

```

- 每条 OCR 结果包含一个四点边框和对应的文本及置信度：

  `[   [[x0, y0], [x1, y1], [x2, y2], [x3, y3]],   (text, confidence) ]`
- 我们关注的关键是：

  1. **文本内容** text
  2. **边框的垂直位置** y0…y3 用来判断是否同一行 [智能文档处理与工作流自动化](https://nanonets.com/blog/image-processing-and-bounding-boxes-for-ocr/?utm_source=chatgpt.com)
  3. **边框的水平位置** x0…x1 用来判断列顺序
